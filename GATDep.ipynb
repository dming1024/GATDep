{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d009c6-ceca-415d-98d6-c46c84b3cf9c",
   "metadata": {},
   "source": [
    "# GATDep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60419dc5-4239-46e8-8f29-d1d0a532d812",
   "metadata": {},
   "source": [
    "## Data preprocess "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d75b1-de22-4ca6-a5b0-5f2bae5241b8",
   "metadata": {},
   "source": [
    "### Download \n",
    "\n",
    "dowload public datasets from `DepMap`, `TCGA`, `GEO`, `DrugComb`, `STRING` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b72d80-4995-453f-9afb-38a3aab13781",
   "metadata": {},
   "source": [
    "#### DepMap\n",
    "\n",
    "[DepMap](https://depmap.org/portal/data_page/?tab=overview)\n",
    "\n",
    "+ CRISPRGeneEffect.csv\n",
    "+ CRISPRInferredCommonEssentials.csv\n",
    "+ Model.csv\n",
    "+ OmicsCNGene.csv\n",
    "+ OmicsExpressionProteinCodingGenesTPMLogp1BatchCorrected.csv\n",
    "+ PortalOmicsCNGeneLog2.csv\n",
    "+ OmicsSomaticMutationsProfile.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb09ae-9e0c-4e70-8ba1-d3c8846ee609",
   "metadata": {},
   "source": [
    "#### TCGA\n",
    "\n",
    "[TCGA](https://www.cancer.gov/ccg/research/genome-sequencing/tcga)\n",
    "\n",
    "[cBioProtal](https://www.cbioportal.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe9652-3328-4b47-bae5-6203eb3a1e1d",
   "metadata": {},
   "source": [
    "#### GEO\n",
    "\n",
    "[GEO](https://www.ncbi.nlm.nih.gov/geo/)\n",
    "\n",
    "+ GSE272107\n",
    "+ GSE259249\n",
    "+ GSE219938/GSE219474\n",
    "+ GSE221475"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90ca99-54b4-4665-9456-277c2ac4e60c",
   "metadata": {},
   "source": [
    "#### DrugComb\n",
    "\n",
    "[DrugComb](https://drugcomb.org/)\n",
    "\n",
    "+ summary_v_1_5.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd6c19-c6da-4036-9335-6d79b0eb1f39",
   "metadata": {},
   "source": [
    "#### STRING\n",
    "\n",
    "[STRING](https://cn.string-db.org/cgi/download?sessionId=bEqmxblRdyEl)\n",
    "\n",
    "+ 9606.protein.links.v10.5.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775156e-00df-4c4b-bca3-b52793bb9527",
   "metadata": {},
   "source": [
    "#### MSigDB\n",
    "\n",
    "[MSigDB](https://www.gsea-msigdb.org/gsea/msigdb/index.jsp)\n",
    "\n",
    "+ C2 category\n",
    "+ C5 category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef41f26-e838-4e07-9981-ae8c5f340550",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b17811-bfc7-406a-a021-222ddb89f250",
   "metadata": {},
   "source": [
    "### GATDep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390737-6084-43f1-af56-09a8db988319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index,data.batch)\n",
    "            preds_all.append(out.cpu().numpy().flatten())\n",
    "            y_all.append(data.y.cpu().numpy().flatten())\n",
    "\n",
    "    y_true = np.concatenate(y_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson = pearsonr(y_true.ravel(), y_pred.ravel())[0]\n",
    "\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'Pearson': pearson}\n",
    "\n",
    "class GeneDependencyGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, heads=2, dropout=0.2):\n",
    "        super(GeneDependencyGAT, self).__init__()\n",
    "    \n",
    "        self.layer = nn.Linear(in_channels, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.1)#0.1,0.2\n",
    "        \n",
    "        #  GAT layers\n",
    "        self.gat1 = GATConv(512, hidden_channels, heads=2, dropout=dropout,concat=True)\n",
    "        self.norm1 = LayerNorm(hidden_channels * 2)\n",
    "\n",
    "        self.gat2 = GATConv(hidden_channels * 2, hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels)\n",
    "\n",
    "        # node level regression head\n",
    "        self.lin = nn.Linear(hidden_channels * 2 , out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = self.layer(x)\n",
    "        x = self.ln1(x)\n",
    "        x = torch.relu(x)#relu,tanh\n",
    "        \n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "\n",
    "        x_global = global_mean_pool(x, batch)               # [num_graphs, hidden_dim]\n",
    "        x_global = x_global[batch]                          # broadcast  [num_nodes, hidden_dim]\n",
    "\n",
    "        x = torch.cat([x, x_global], dim=1)                 # [num_nodes, hidden*2]\n",
    "        out = self.lin(x)\n",
    "        return out    \n",
    "    \n",
    "model = GeneDependencyGAT(in_channels=6561, hidden_channels=64, out_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e938c-af0a-44e0-b88e-7361b5477fde",
   "metadata": {},
   "source": [
    "### GATDep_Mut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f3106-d860-47db-8283-56f8089b0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# === Loss functions ===\n",
    "huber_loss = nn.HuberLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    loss_es = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.x_mut,data.edge_index,data.batch)\n",
    "            preds_all.append(out.cpu().numpy().flatten())\n",
    "            y_all.append(data.y.cpu().numpy().flatten())\n",
    "            loss = huber_loss(out, data.y)\n",
    "            loss_es.append(loss.item())\n",
    "            \n",
    "    \n",
    "    #y_true = torch.cat(preds_all, dim=0).numpy() #np.concatenate(y_all)\n",
    "    #y_pred = torch.cat(y_all, dim=0).numpy()#np.concatenate(preds_all)\n",
    "    y_true = np.concatenate(y_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "\n",
    "    loss = np.mean(loss_es)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson = pearsonr(y_true.ravel(), y_pred.ravel())[0]\n",
    "\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'Pearson': pearson,'Loss':loss}\n",
    "\n",
    "class MutationLayer(nn.Module):\n",
    "    def __init__(self, embed_dim=32, hidden_dim=256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim\n",
    "            hidden_dim\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.embed = nn.Linear(1, embed_dim)  \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.LazyLinear(hidden_dim),  # input shape\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, 2350, 1] or [batch_size, 2350] (float tensor)\n",
    "        Returns:\n",
    "            [batch_size, hidden_dim] \n",
    "        \"\"\"\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)  # [batch, 2350] -> [batch, 2350, 1]\n",
    "        \n",
    "        x = self.embed(x)  # [batch, 2350, embed_dim]\n",
    "        \n",
    "        x = x.mean(dim=1)  # [batch, embed_dim]\n",
    "        \n",
    "        return self.encoder(x)\n",
    "\n",
    "class GeneDependencyGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, heads=4, dropout=0.2):\n",
    "        super(GeneDependencyGAT, self).__init__()\n",
    "    \n",
    "        self.layer = nn.Linear(in_channels, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.1)#0.1,0.2\n",
    "        \n",
    "        #add mutation features extraction layer\n",
    "        self.mut_layer = MutationLayer(embed_dim=32, hidden_dim=128)\n",
    "        \n",
    "        #self.gat1 = GATConv(512, hidden_channels, heads=2, dropout=dropout,concat=True)\n",
    "        self.gat1 = GATConv(640, hidden_channels, heads=2, dropout=dropout,concat=True) # 512+128 -》 640\n",
    "        self.norm1 = LayerNorm(hidden_channels * 2)\n",
    "\n",
    "        self.gat2 = GATConv(hidden_channels * 2, hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels)\n",
    "\n",
    "        self.lin = nn.Linear(hidden_channels * 2 , out_channels)\n",
    "\n",
    "    def forward(self, x,x_mut, edge_index, batch):\n",
    "        \n",
    "        x = self.layer(x)\n",
    "        x = self.ln1(x)\n",
    "        x = torch.relu(x)#relu,tanh\n",
    "        \n",
    "        #add mutation features\n",
    "        x_mut=self.mut_layer(x_mut)\n",
    "        x = torch.cat([x, x_mut], dim=1)#cat MUT and EXP into one: 2350 x (512+128)\n",
    "        \n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x_global = global_mean_pool(x, batch)               # [num_graphs, hidden_dim]\n",
    "        x_global = x_global[batch]                          # broadcast [num_nodes, hidden_dim]\n",
    "\n",
    "        x = torch.cat([x, x_global], dim=1)                 # [num_nodes, hidden*2]\n",
    "        out = self.lin(x)\n",
    "        return out    \n",
    "    \n",
    "model = GeneDependencyGAT(in_channels=6561, hidden_channels=64, out_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4d26d-fbf0-4077-af06-552bb0a20bca",
   "metadata": {},
   "source": [
    "### GATDep_Mut_CNV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a26fd-998f-4d2d-b32d-771bc3b97868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "huber_loss = nn.HuberLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    loss_es = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.x_mut,data.x_cnv,data.edge_index,data.batch)\n",
    "            preds_all.append(out.cpu().numpy().flatten())\n",
    "            y_all.append(data.y.cpu().numpy().flatten())\n",
    "            loss = huber_loss(out, data.y)\n",
    "            loss_es.append(loss.item())\n",
    "            \n",
    "    y_true = np.concatenate(y_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "\n",
    "    loss = np.mean(loss_es)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson = pearsonr(y_true.ravel(), y_pred.ravel())[0]\n",
    "\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'Pearson': pearson,'Loss':loss}\n",
    "\n",
    "class MutationLayer(nn.Module):\n",
    "    def __init__(self, embed_dim=32, hidden_dim=256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim\n",
    "            hidden_dim\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "\n",
    "        self.embed = nn.Linear(1, embed_dim)  \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.LazyLinear(hidden_dim),  \n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, 2350, 1] or [batch_size, 2350] \n",
    "        Returns:\n",
    "            [batch_size, hidden_dim] \n",
    "        \"\"\"\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)  # [batch, 2350] -> [batch, 2350, 1]\n",
    "        \n",
    "        x = self.embed(x)  # [batch, 2350, embed_dim]\n",
    "        \n",
    "        x = x.mean(dim=1)  # [batch, embed_dim]\n",
    "        \n",
    "        return self.encoder(x)\n",
    "\n",
    "class GeneDependencyGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, heads=4, dropout=0.2):\n",
    "        super(GeneDependencyGAT, self).__init__()\n",
    "    \n",
    "        self.layer = nn.Linear(in_channels, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.1)#0.1,0.2\n",
    "        \n",
    "        #mutation layer\n",
    "        self.mut_layer = MutationLayer(embed_dim=32, hidden_dim=128)\n",
    "        #cnv layer\n",
    "        self.CNV_layer = MutationLayer(embed_dim=32, hidden_dim=128)\n",
    "        \n",
    "        self.gat1 = GATConv(768, hidden_channels, heads=2, dropout=dropout,concat=True) #512+128+128 -> 768\n",
    "        self.norm1 = LayerNorm(hidden_channels * 2)\n",
    "\n",
    "        self.gat2 = GATConv(hidden_channels * 2, hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels)\n",
    "\n",
    "        self.lin = nn.Linear(hidden_channels * 2 , out_channels)\n",
    "\n",
    "    def forward(self,x,x_mut,x_cnv, edge_index, batch):\n",
    "        \n",
    "        x = self.layer(x)\n",
    "        x = self.ln1(x)\n",
    "        x = torch.relu(x)#relu,tanh\n",
    "        \n",
    "        #add mut, cnv features\n",
    "        x_mut=self.mut_layer(x_mut)\n",
    "        x_cnv=self.CNV_layer(x_cnv)\n",
    "        x = torch.cat([x, x_mut,x_cnv], dim=1)#cat Exp, Mut, CNV into 2350 x (512+128+128)\n",
    "        \n",
    "        \n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x_global = global_mean_pool(x, batch)               # [num_graphs, hidden_dim]\n",
    "        x_global = x_global[batch]                          # broadcast  [num_nodes, hidden_dim]\n",
    "\n",
    "        x = torch.cat([x, x_global], dim=1)                 # [num_nodes, hidden*2]\n",
    "        out = self.lin(x)\n",
    "        return out    \n",
    "    \n",
    "model = GeneDependencyGAT(in_channels=6561, hidden_channels=64, out_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68063f6b-fad2-40c4-b8a9-3f3ef79dc34b",
   "metadata": {},
   "source": [
    "### DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50731728-8e66-4a3d-9830-851377bfb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=nn.Sequential(\n",
    "\n",
    "nn.Linear(6561,512),\n",
    "nn.LayerNorm(512),\n",
    "nn.ReLU(),\n",
    "nn.Dropout(0.2),\n",
    "\n",
    "nn.Linear(512,128),\n",
    "nn.LayerNorm(128),\n",
    "nn.ReLU(),\n",
    "nn.Dropout(0.2),\n",
    "\n",
    "nn.Linear(128,1),\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93b711-0846-46b6-a0b3-118e9d557fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5138cbca-33c9-40d1-8d74-3212171e7cf7",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d4f63-9b3b-47c1-a970-e55b3a609beb",
   "metadata": {},
   "source": [
    "### GATDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ff874-b8b7-43e2-b8c3-f563f0c0d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_max_pool\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_max_pool\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ppi_df = pd.read_csv(\"./datasets/ggi_id.txt\", sep=\" \")\n",
    "edges = ppi_df[['g1_id', 'g2_id']].values\n",
    "edge_index = torch.tensor(edges.T, dtype=torch.long) \n",
    "\n",
    "with open(r'./datasets/genes2ID_2k.json', 'r', encoding='utf-8') as file:\n",
    "    genes2ID_2k = json.load(file)\n",
    "with open(r'./datasets/samples2ID.json', 'r', encoding='utf-8') as file:\n",
    "    samples2ID = json.load(file)    \n",
    "gene_geneset=np.load(r\"./datasets/adj_gene_geneset.npy\")\n",
    "gsva = np.load(r\"./datasets/gsva_score_go_kegg_v3_format.npy\")\n",
    "crispr_score = np.genfromtxt(r\"./datasets/crispr_score_v4_20250423_scale_in_each_sample.txt\", \n",
    "                     dtype=str, delimiter=' ', \n",
    "                     skip_header=1, filling_values='', \n",
    "                     autostrip=True) #(2556800, 4)#格式化后的数据\n",
    "                     \n",
    "def get_train_test_dataset(crispr_dataset):\n",
    "    samples=list(np.unique(crispr_dataset[:,0])) #CRISPR数据中的样本\n",
    "    score_list=[]\n",
    "    gene_feature_list=[]\n",
    "    \n",
    "    for sample in samples:\n",
    "        score,gene_feature=get_score_and_gene_features_per_sample(sample,crispr_dataset)\n",
    "        score_list.append(score)\n",
    "        gene_feature_list.append(gene_feature)\n",
    "    \n",
    "    return gene_feature_list,score_list\n",
    "\n",
    "def get_score_and_gene_features_per_sample(sample,crispr_score):\n",
    "    tmp=[]\n",
    "    for gene in genes2ID_2k.keys():\n",
    "        tmp.append(gene_geneset[genes2ID_2k[gene],:] * gsva[samples2ID[sample]])\n",
    "        #返回一个样本，所有gene(2350)的特征信息(6561)：\n",
    "    \n",
    "    #获取每个样本的数据\n",
    "    crispr_score_sample=crispr_score[crispr_score[:,0]==sample,]    \n",
    "    # 提取排序的列（第0列）\n",
    "    sort_column = crispr_score_sample[:, 1]    \n",
    "    # 生成排序索引（根据字典映射的权重）\n",
    "    sort_indices = np.argsort([genes2ID_2k[x] for x in sort_column])    \n",
    "    # 按索引重新排列数组\n",
    "    sorted_crispr_score_sample = crispr_score_sample[sort_indices]\n",
    "    # 单个样本中2k+ 基因score值\n",
    "    score_per_sample=np.array([np.round(np.float32(m),4) for m in sorted_crispr_score_sample[:,2]]).reshape(-1,1) #(2350, 1)\n",
    "\n",
    "    return score_per_sample,np.array(tmp)\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index,data.batch)\n",
    "            preds_all.append(out.cpu().numpy().flatten())\n",
    "            y_all.append(data.y.cpu().numpy().flatten())\n",
    "    \n",
    "    #y_true = torch.cat(preds_all, dim=0).numpy() #np.concatenate(y_all)\n",
    "    #y_pred = torch.cat(y_all, dim=0).numpy()#np.concatenate(preds_all)\n",
    "    y_true = np.concatenate(y_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "\n",
    "    #loss = nn.HuberLoss()(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson = pearsonr(y_true.ravel(), y_pred.ravel())[0]\n",
    "\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'Pearson': pearson}\n",
    "\n",
    "class GeneDependencyGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1, heads=4, dropout=0.2):\n",
    "        super(GeneDependencyGAT, self).__init__()\n",
    "    \n",
    "        self.layer = nn.Linear(in_channels, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.1)#0.1,0.2\n",
    "        \n",
    "        # 两层 GAT\n",
    "        self.gat1 = GATConv(512, hidden_channels, heads=2, dropout=dropout,concat=True)\n",
    "        self.norm1 = LayerNorm(hidden_channels * 2)\n",
    "\n",
    "        self.gat2 = GATConv(hidden_channels * 2, hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels)\n",
    "\n",
    "        # 节点级别回归头\n",
    "        self.lin = nn.Linear(hidden_channels * 2 , out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x: [N_nodes, in_channels]\n",
    "        # edge_index: [2, E]\n",
    "        # batch: [N_nodes], 如果需要处理多个图\n",
    "        \n",
    "        x = self.layer(x)\n",
    "        x = self.ln1(x)\n",
    "        x = torch.relu(x)#relu,tanh\n",
    "        \n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # 获取图级全局信息\n",
    "        x_global = global_mean_pool(x, batch)               # [num_graphs, hidden_dim]\n",
    "        x_global = x_global[batch]                          # broadcast 到每个节点 [num_nodes, hidden_dim]\n",
    "\n",
    "        x = torch.cat([x, x_global], dim=1)                 # [num_nodes, hidden*2]\n",
    "        out = self.lin(x)\n",
    "        #out = self.lin(x)  # 输出节点级别预测值 [N_nodes, 1]\n",
    "        #return out.squeeze(-1)  # [N_nodes]\n",
    "        return out    \n",
    "    \n",
    "for k in np.arange(10):\n",
    "    print(f'kx: {k+1}')\n",
    "    crispr_score_test=crispr_score[crispr_score[:,3]==str(k+1),:]\n",
    "    crispr_score_train=crispr_score[crispr_score[:,3]!=str(k+1),:]\n",
    "    #path_to_save_model='models/best_model_v1_basedon_v4_scale_data.pt'\n",
    "    model = GeneDependencyGAT(in_channels=6561, hidden_channels=64, out_channels=1)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    path_to_save_model=f'trained_models/best_model_k_{k+1}_basedon_v4_scale_data.pt'\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    early_stop_patience = 10\n",
    "    num_epochs=150\n",
    "    \n",
    "    gene_feature_list,score_list=get_train_test_dataset(crispr_score_train)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(gene_feature_list, score_list, test_size=0.2, random_state=42)\n",
    "\n",
    "    data_list_val = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(X_val,y_val)]\n",
    "    val_loader = DataLoader(data_list_val, batch_size=5)\n",
    "\n",
    "    data_list_train = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(X_train,y_train)]\n",
    "    train_loader = DataLoader(data_list_train, batch_size=5, shuffle=True)    \n",
    "    \n",
    "    gene_feature_list_test,score_list_test=get_train_test_dataset(crispr_score_test)\n",
    "    data_list_test = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(gene_feature_list_test,score_list_test)]\n",
    "    test_loader = DataLoader(data_list_test, batch_size=5)\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            batch.x, batch.edge_index, batch.batch = batch.x.to(device), batch.edge_index.to(device), batch.batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss = F.huber_loss(out.cpu(), batch.y,delta=1.0)\n",
    "            #loss = 0.8*negative_pearson_loss(out, batch.y) + 0.3*F.huber_loss(out, batch.y,delta=1.0)\n",
    "            #loss = compute_loss(out, batch.y) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "        val_metrics = evaluate(model, val_loader)\n",
    "        train_metrics = evaluate(model, train_loader)\n",
    "        val_loss = val_metrics['MSE']\n",
    "        \n",
    "        test_metrics = evaluate(model, test_loader)\n",
    "        test_loss = test_metrics['MSE']\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {loss.item():.4f} | \\\n",
    "        Train MSE: {train_metrics['MSE']:.4f} | \\\n",
    "        Val MSE: {val_metrics['MSE']:.4f} | \\\n",
    "        Train MAE: {train_metrics['MAE']:.4f} | \\\n",
    "        Val MAE: {val_metrics['MAE']:.4f} | \\\n",
    "        learning rate: {current_lr} | \\\n",
    "        Train R2: {train_metrics['R2']:.4f} | \\\n",
    "        Val R2: {val_metrics['R2']:.4f} | \\\n",
    "        Train Pearson: {train_metrics['Pearson']:.4f} | \\\n",
    "        Val Pearson: {val_metrics['Pearson']:.4f} | \\\n",
    "        Test MSE: {test_metrics['MSE']:.4f} | \\\n",
    "        Test MAE: {test_metrics['MAE']:.4f} | \\\n",
    "        Test R2: {test_metrics['R2']:.4f} | \\\n",
    "        Test Pearson: {test_metrics['Pearson']:.4f} \")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), path_to_save_model)  # 可选保存,持续的保存优化的模型\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9db09-4d68-4315-ac5e-68dd5f8c4dca",
   "metadata": {},
   "source": [
    "### DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35af685-d340-405e-a4e0-6b662154ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_max_pool\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(r'datasets/genes2ID_2k.json', 'r', encoding='utf-8') as file:\n",
    "    genes2ID_2k = json.load(file)\n",
    "with open(r'datasets/samples2ID.json', 'r', encoding='utf-8') as file:\n",
    "    samples2ID = json.load(file)    \n",
    "gene_geneset=np.load(r\"datasets/adj_gene_geneset.npy\")\n",
    "gsva = np.load(r\"datasets/gsva_score_go_kegg_v3_format.npy\")\n",
    "crispr_score = np.genfromtxt(r\"datasets/crispr_score_v4_20250423_scale_in_each_sample.txt\", \n",
    "                     dtype=str, delimiter=' ', \n",
    "                     skip_header=1, filling_values='', \n",
    "                     autostrip=True) #(2556800, 4)#格式化后的数据\n",
    "                     \n",
    "\n",
    "def get_score_and_gene_features_per_sample(sample,crispr_score):\n",
    "    tmp=[]\n",
    "    for gene in genes2ID_2k.keys():\n",
    "        tmp.append(gene_geneset[genes2ID_2k[gene],:] * gsva[samples2ID[sample]])\n",
    "\n",
    "    crispr_score_sample=crispr_score[crispr_score[:,0]==sample,]    \n",
    "    sort_column = crispr_score_sample[:, 1]    \n",
    "    sort_indices = np.argsort([genes2ID_2k[x] for x in sort_column])    \n",
    "    sorted_crispr_score_sample = crispr_score_sample[sort_indices]\n",
    "    score_per_sample=np.array([np.round(np.float32(m),4) for m in sorted_crispr_score_sample[:,2]]).reshape(-1,1) #(2350, 1)\n",
    "\n",
    "    return score_per_sample,np.array(tmp)\n",
    "\n",
    "def get_train_test_dataset(crispr_dataset):\n",
    "    samples=list(np.unique(crispr_dataset[:,0])) #CRISPR数据中的样本\n",
    "    score_list=[]\n",
    "    gene_feature_list=[]\n",
    "    \n",
    "    for sample in samples:\n",
    "        score,gene_feature=get_score_and_gene_features_per_sample(sample,crispr_dataset)\n",
    "        score_list.append(score)\n",
    "        gene_feature_list.append(gene_feature)\n",
    "    \n",
    "    return gene_feature_list,score_list\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "# === Loss functions ===\n",
    "huber_loss = nn.HuberLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "\n",
    "# === Early stopping ===\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stop_patience = 10\n",
    "huber_loss = nn.HuberLoss()\n",
    "\n",
    "def combined_loss(pred, true):\n",
    "    # pred, true: (batch_size, num_genes)\n",
    "    pred_centered = pred - pred.mean(dim=0, keepdim=True)\n",
    "    true_centered = true - true.mean(dim=0, keepdim=True)\n",
    "\n",
    "    numerator = (pred_centered * true_centered).sum(dim=0)\n",
    "    denominator = torch.sqrt((pred_centered**2).sum(dim=0)) * torch.sqrt((true_centered**2).sum(dim=0))\n",
    "    corr = numerator / (denominator + 1e-8)\n",
    "\n",
    "    loss_samplewise = nn.SmoothL1Loss()(pred, true)\n",
    "    return loss_samplewise + 1 - corr.mean()\n",
    "\n",
    "# === Training function ===\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    loss_es = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            loss = huber_loss(preds, y)\n",
    "            preds_all.append(preds.cpu().numpy().flatten())\n",
    "            y_all.append(y.cpu().numpy().flatten())\n",
    "            loss_es.append(loss.item())\n",
    "    \n",
    "    y_true = np.concatenate(y_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "\n",
    "    loss = np.mean(loss_es)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson = pearsonr(y_true.ravel(), y_pred.ravel())[0]\n",
    "\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'Pearson': pearson,'Loss':loss}\n",
    "    \n",
    "#num_epochs = 150\n",
    "#path_to_save_model='models/best_model_dnn_v2.pt'\n",
    "logs={\n",
    "'k':[0],\n",
    "'Epoch':[0],\n",
    "'Train_MSE':[0],\n",
    "'Val_MSE': [0],\n",
    "'Test_MSE': [0],\n",
    "\n",
    "'Train_MAE': [0],\n",
    "'Val_MAE': [0],\n",
    "'Test_MAE': [0],\n",
    "\n",
    "'Learning_rate': [0],\n",
    "'Train_R2': [0],\n",
    "'Val_R2': [0],\n",
    "'Test_R2': [0],\n",
    "\n",
    "'Train_Pearson': [0],\n",
    "'Val_Pearson': [0],\n",
    "'Test_Pearson': [0],\n",
    "\n",
    "'Train_Loss': [0],\n",
    "'Val_Loss': [0],\n",
    "'Test_Loss': [0]\n",
    "}\n",
    "\n",
    "for k in np.arange(10):\n",
    "    crispr_score_test=crispr_score[crispr_score[:,3]==str(k+1),:]\n",
    "    crispr_score_train=crispr_score[crispr_score[:,3]!=str(k+1),:]\n",
    "    \n",
    "    model=nn.Sequential(\n",
    "    nn.Linear(6561,512),\n",
    "    nn.LayerNorm(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(512,128),\n",
    "    nn.LayerNorm(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(128,1),\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    # === Optimizer & Scheduler ===\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    path_to_save_model=f'trained_models/best_model_k{k+1}_DNN_scale_data.pt'\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    early_stop_patience = 10\n",
    "    num_epochs=150\n",
    "    \n",
    "    gene_feature_list,score_list=get_train_test_dataset(crispr_score_train)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(gene_feature_list, score_list, test_size=0.2, random_state=42)\n",
    "\n",
    "    #data_list_val = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(X_val,y_val)]\n",
    "    data_list_val=TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                            torch.tensor(y_val, dtype=torch.float32))\n",
    "    val_loader = DataLoader(data_list_val, batch_size=5)\n",
    "\n",
    "    #data_list_train = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(X_train,y_train)]\n",
    "    data_list_train=TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(data_list_train, batch_size=5, shuffle=True)    \n",
    "    \n",
    "    gene_feature_list_test,score_list_test=get_train_test_dataset(crispr_score_test)\n",
    "    #data_list_test = [Data(x=torch.from_numpy(x_i), edge_index=edge_index, y=torch.from_numpy(y_i)) for x_i,y_i in zip(gene_feature_list_test,score_list_test)]\n",
    "    data_list_test=TensorDataset(torch.tensor(gene_feature_list_test, dtype=torch.float32),\n",
    "                              torch.tensor(score_list_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(data_list_test, batch_size=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            preds = model(x_batch)       \n",
    "            #loss = huber_loss(preds, y_batch) + mse_loss(preds, y_batch)\n",
    "            loss = huber_loss(preds, y_batch)\n",
    "            #loss = combined_loss(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #total_loss += loss.item()\n",
    "\n",
    "        # === Evaluate on validation set ===\n",
    "        val_metrics = evaluate(model, val_loader)\n",
    "        val_loss = val_metrics['Loss'] \n",
    "        \n",
    "        train_metrics = evaluate(model, train_loader)\n",
    "        test_metrics = evaluate(model, test_loader)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        #print(f\"[Epoch {epoch+1}] Train Loss: {total_loss:.4f} |Learning Rate: {current_lr}|Val Loss : {val_loss:.4f} |Val MSE: {val_metrics['MSE']:.4f} | R2: {val_metrics['R2']:.4f} | Pearson: {val_metrics['Pearson']:.4f}\")\n",
    "        logs['k'].append(k+1)\n",
    "        logs['Epoch'].append(epoch+1)\n",
    "        logs['Train_MSE'].append(train_metrics['MSE'])\n",
    "        logs['Val_MSE'].append(val_metrics['MSE'])\n",
    "        logs['Test_MSE'].append(test_metrics['MSE'])\n",
    "        \n",
    "        logs['Train_MAE'].append(train_metrics['MAE'])\n",
    "        logs['Val_MAE'].append(val_metrics['MAE'])\n",
    "        logs['Test_MAE'].append(test_metrics['MAE'])\n",
    "        \n",
    "        logs['Learning_rate'].append(current_lr)\n",
    "        \n",
    "        logs['Train_R2'].append(train_metrics['R2'])\n",
    "        logs['Val_R2'].append(val_metrics['R2'])\n",
    "        logs['Test_R2'].append(test_metrics['R2'])\n",
    "        \n",
    "        logs['Train_Pearson'].append(train_metrics['Pearson'])\n",
    "        logs['Val_Pearson'].append(val_metrics['Pearson'])\n",
    "        logs['Test_Pearson'].append(test_metrics['Pearson'])\n",
    "        \n",
    "        logs['Train_Loss'].append(train_metrics['Loss'])\n",
    "        logs['Val_Loss'].append(val_metrics['Loss'])\n",
    "        logs['Test_Loss'].append(test_metrics['Loss'])\n",
    "        \n",
    "        \n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        # === Early stopping ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), path_to_save_model) \n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                pd.DataFrame(logs).to_csv(f'./logs/logs_k{k+1}.csv')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c1235-f47f-403d-9b53-15746d400e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db094381-dcc1-4055-bea9-2620998b8e6d",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4001bfa-43fa-4e29-919d-a420ec9407f2",
   "metadata": {},
   "source": [
    "### GSE272107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb42ad8-0350-4535-8b47-498fc5c976de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GSVA results\n",
    "gsva_scores_df=pd.read_csv(r\"GSE272107_gsva.txt\",delimiter=' ')\n",
    "with open(r'datasets/genesets_select_6k.json', 'r', encoding='utf-8') as file:\n",
    "    geneset2ID = json.load(file)\n",
    "\n",
    "def get_rows_with_fallback(df, row_names):\n",
    "    existing = df.reindex(row_names).fillna(0)\n",
    "    return existing\n",
    "result_df = get_rows_with_fallback(gsva_scores_df.T, geneset2ID.keys())\n",
    "gsva_scores_GSE272107=np.array(result_df.T,dtype='float32') # sample X 6561\t\n",
    "def get_gene_features_per_sample(sample):\n",
    "    tmp=[]\n",
    "    for gene in genes2ID_2k.keys():\n",
    "        tmp.append(gene_geneset[genes2ID_2k[gene],:] * gsva_scores_GSE272107[sample])\n",
    "    return np.array(tmp)\n",
    "\n",
    "samples=np.arange(10)\n",
    "score_list=[]\n",
    "gene_feature_list=[]\n",
    "\n",
    "for sample in samples:\n",
    "    gene_feature=get_gene_features_per_sample(sample)\n",
    "    #score_list.append(score)\n",
    "    gene_feature_list.append(gene_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4eaa21-8813-49f1-9cb0-17d12d064a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_GSE272107 = [Data(x=torch.from_numpy(x_i), edge_index=edge_index) for x_i in gene_feature_list]\n",
    "data_list_GSE272107_loader = DataLoader(data_list_GSE272107, batch_size=5)\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in data_list_GSE272107_loader:\n",
    "    #for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index,data.batch)\n",
    "        all_preds.append(out.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1177f6e-8bbe-48de-9906-1a81d9def40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(all_preds, dim=0).numpy()\n",
    "pd.DataFrame({\n",
    "    'preds': y_pred.flatten()\n",
    "}).to_csv('GSE272107_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017307b-728b-4666-be82-fb6cc91d7899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf3ae0e8-28ef-4da1-b27b-c1d00695f1f1",
   "metadata": {},
   "source": [
    "## GNNExplainer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51180dcd-3de1-4861-982c-b64f0f400bec",
   "metadata": {},
   "source": [
    "### select node/gene and graph/sample for GNNExplanier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6393908-638e-400c-8a96-8c957d53c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select node/gene and graph/sample for GNNExplanier\n",
    "score_list=[]\n",
    "gene_feature_list=[]\n",
    "samples = ['ACH-000587','ACH-000448']\n",
    "node_idx_in_graph=local_node_idx=921 # egfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65cefe-b52a-44b4-ad23-930677d9b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    score,gene_feature=get_score_and_gene_features_per_sample(sample)\n",
    "    score_list.append(score)\n",
    "    gene_feature_list.append(gene_feature)\n",
    "    \n",
    "ppi_df = pd.read_csv(\"./datasets/ggi_id.txt\", sep=\" \")\n",
    "edges = ppi_df[['g1_id', 'g2_id']].values\n",
    "edge_index = torch.tensor(edges.T, dtype=torch.long) \n",
    "\n",
    "data_list_train = [Data(x=torch.from_numpy(x_i), \n",
    "                        edge_index=edge_index, \n",
    "                        y=torch.from_numpy(y_i))   for x_i,y_i in zip(gene_feature_list,score_list) ]\n",
    "train_loader = DataLoader(data_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66658203-7d97-47ad-960d-d36b0a0b5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_index=0\n",
    "#node_idx_in_graph=local_node_idx=921 # egfr\n",
    "def get_global_node_index_from_local(data, graph_index, local_node_idx):\n",
    "    node_indices = (data.batch == graph_index).nonzero(as_tuple=False).view(-1)\n",
    "    return int(node_indices[local_node_idx].item())\n",
    "\n",
    "data = next(iter(train_loader))\n",
    "global_node_idx = get_global_node_index_from_local(data, graph_index, local_node_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148af41-2492-4837-b417-c229d2936a0a",
   "metadata": {},
   "source": [
    "### Explainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a3da5-7d2c-48c6-ba71-8e4f440b58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GeneDependencyGAT(in_channels=6561, hidden_channels=64, out_channels=1)\n",
    "model.load_state_dict(torch.load('./trained_models/GATDep/best_model_v1_basedon_v4_scale_data.pt'))\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=100),\n",
    "    explanation_type='model',\n",
    "    model_config=ModelConfig(\n",
    "        mode='regression',  \n",
    "        task_level='node', \n",
    "        return_type='raw', \n",
    "    ),\n",
    "    node_mask_type='object',   \n",
    "    edge_mask_type='object',  \n",
    ")\n",
    "\n",
    "explanation = explainer(\n",
    "    x=data.x,\n",
    "    edge_index=data.edge_index,\n",
    "    batch=data.batch,\n",
    "    index=global_node_idx  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe52c5-8266-4f08-a23f-8eabb90c50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. subset node importance\n",
    "importance = node_mask.detach().cpu().numpy()\n",
    "node_color = {}\n",
    "for i, score in enumerate(importance):\n",
    "    if score >= 0.05:\n",
    "        node_color[i] = score\n",
    "if node_idx_in_graph is not None:\n",
    "        node_color[node_idx_in_graph] = np.array(node_mask[node_idx_in_graph])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae122e-46e8-4125-83c7-2f28367b95a8",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e439f-6ab0-451c-a2df-8d33b9dab75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. top 20 genes\n",
    "top_nodes = sorted(node_color.items(), key=lambda x: -x[1])[:20] \n",
    "node_color = dict(top_nodes)\n",
    "node_color[node_idx_in_graph] = np.array(node_mask[node_idx_in_graph])\n",
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0eae0-e78f-4376-a6b3-ec5f9122a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = edge_index.cpu().numpy().T.tolist()\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edge_list)\n",
    "    \n",
    "subG1 = G.subgraph(node_color.keys()).copy()\n",
    "pos = nx.spring_layout(subG1, seed=42)\n",
    "\n",
    "#获取node_labels\n",
    "node_labels={}\n",
    "for k,v in node_color.items():\n",
    "    node_labels[k]=id2gene[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0fb6c-63ac-4af8-8064-43bcc199110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subG = G.subgraph(node_color.keys()).copy()\n",
    "\n",
    "pos = nx.spring_layout(subG, seed=42,k=0.9)\n",
    "#cmap = plt.cm.viridis\n",
    "from matplotlib.colors import Normalize, LinearSegmentedColormap\n",
    "cmap = LinearSegmentedColormap.from_list(\"my_colormap\", [\"grey\",\"white\", \"#548235\"])\n",
    "\n",
    "values = list(node_color.values())\n",
    "nodes = list(node_color.keys())\n",
    "\n",
    "norm = plt.Normalize(vmin=min(values), vmax=max(values))\n",
    "\n",
    "#plt.figure(figsize=(8, 6))\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  \n",
    "nx.draw_networkx_edges(subG, pos, alpha=0.5)\n",
    "nodes_drawn = nx.draw_networkx_nodes(\n",
    "    subG, pos, nodelist=nodes,\n",
    "    node_color=[node_color[n] for n in nodes],\n",
    "    cmap=cmap,\n",
    "    node_size=2000,\n",
    "    alpha=0.9,\n",
    "    linewidths=0,\n",
    "    edgecolors=\"black\"\n",
    ")\n",
    "nx.draw_networkx_nodes(\n",
    "            subG, pos, nodelist=[local_node_idx],\n",
    "            node_color='grey',\n",
    "            node_size=2000,\n",
    "            label='Center Node',\n",
    "            edgecolors=\"darkred\"\n",
    "        )\n",
    "nx.draw_networkx_edges(subG,pos, width=3)\n",
    "nx.draw_networkx_labels(subG, pos, font_size=18, \n",
    "                        font_color=\"black\",\n",
    "                        #font_family='arial',\n",
    "                       labels=node_labels)\n",
    "#nx.draw_networkx_labels(subG, pos1, font_size=10, font_color=\"white\")\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax,shrink=0.8,aspect=20)\n",
    "#cbar.ax.set_aspect(20)\n",
    "cbar.set_label('Node Importance (mask)',size=20)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "ax.set_title('')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'gene_id_{id2gene[local_node_idx]}_{local_node_idx}.png',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422710d6-34f2-4dff-928b-b657f2cc28fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdc3d9-45cf-4d42-9237-e20d07f3baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
